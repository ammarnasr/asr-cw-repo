{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### import os\n",
    "import wer\n",
    "import openfst_python as fst\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from vetrbi import MyViterbiDecoder\n",
    "from utils import parse_lexicon, generate_symbol_tables\n",
    "from hmm import generate_word_sequence_recognition_wfst\n",
    "from hmm import generate_word_sequence_recognition_wfst_with_silance\n",
    "from utils import draw\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "\n",
    "def create_wfst():\n",
    "    f = generate_word_sequence_recognition_wfst(3)\n",
    "    f.set_input_symbols(state_table)\n",
    "    f.set_output_symbols(phone_table)\n",
    "    return f\n",
    "\n",
    "def create_wfst_with_silance():\n",
    "    f = generate_word_sequence_recognition_wfst_with_silance(3, use_unigram_probs=False)\n",
    "    f.set_input_symbols(state_table)\n",
    "    f.set_output_symbols(phone_table)\n",
    "    return f\n",
    "\n",
    "\n",
    "def read_transcription(wav_file):\n",
    "    \"\"\"\n",
    "    Get the transcription corresponding to wav_file.\n",
    "    \"\"\"\n",
    "    \n",
    "    transcription_file = os.path.splitext(wav_file)[0] + '.txt'\n",
    "    \n",
    "    with open(transcription_file, 'r') as f:\n",
    "        transcription = f.readline().strip()\n",
    "    \n",
    "    return transcription\n",
    "\n",
    "def memory_of_wfst(f):\n",
    "    '''\n",
    "    Compute a measure of the memory required for your decoder by providing counts\n",
    "    of number of states and arcs in the WFST.\n",
    "    '''\n",
    "    all_states = []\n",
    "    all_arcs = []\n",
    "    for state in f.states():\n",
    "        all_states.append(state)\n",
    "        for arc in f.arcs(state):\n",
    "            all_arcs.append(arc)\n",
    "    return len(all_states), len(all_arcs)\n",
    "    \n",
    "def get_avg_wer(all_losses, verbose=False):\n",
    "    all_wer = []\n",
    "    for error_counts, word_count in all_losses:\n",
    "        all_wer.append(sum(error_counts) / word_count)\n",
    "    \n",
    "    if verbose :\n",
    "        print(f'The average WER is {np.mean(all_wer):.2%}')    \n",
    "    return np.mean(all_wer)\n",
    "\n",
    "def get_avg_effciency(efficancy_measures, verbose=False):\n",
    "    decoding_time = np.mean(efficancy_measures[0])\n",
    "    backtrace_time = np.mean(efficancy_measures[1])\n",
    "    number_of_computions = np.mean(efficancy_measures[2])\n",
    "    if verbose:\n",
    "        print(f'The average decoding time is {decoding_time:.2f} seconds')\n",
    "        print(f'The average backtrace time is {backtrace_time:.2f} seconds')\n",
    "        print(f'The average number of computations is {number_of_computions:.2f}')\n",
    "    return decoding_time, backtrace_time, number_of_computions\n",
    "\n",
    "\n",
    "def decoding_loop(f, train_set=True, train_split=0.85, use_pruning=False, determinized=False, verbose=False, prune_threshold= None):\n",
    "    all_losses = []\n",
    "    decoding_time = []\n",
    "    backtrace_time = []\n",
    "    number_of_computations = []\n",
    "    all_files = glob.glob('/group/teaching/asr/labs/recordings/*.wav')\n",
    "    train_files = all_files[:(int(train_split*len(all_files)))]\n",
    "    test_files = all_files[(int(train_split*len(all_files))):]\n",
    "    \n",
    "    if train_set:\n",
    "        files= train_files\n",
    "    else:\n",
    "        files = test_files\n",
    "    \n",
    "    for wav_file in tqdm(files):    \n",
    "        decoder  = MyViterbiDecoder(f, wav_file, verbose=verbose, use_pruning=use_pruning, determinized=determinized)\n",
    "        if use_pruning and prune_threshold!=None:\n",
    "            decoder.prune_threshold = prune_threshold\n",
    "        decoder.decode()\n",
    "        (state_path, words) = decoder.backtrace()  \n",
    "        transcription = read_transcription(wav_file)\n",
    "        error_counts = wer.compute_alignment_errors(transcription, words)\n",
    "        word_count = len(transcription.split())\n",
    "\n",
    "        all_losses.append((error_counts, word_count))\n",
    "        decoding_time.append(decoder.decode_time)\n",
    "        backtrace_time.append(decoder.backtrace_time)\n",
    "        number_of_computations.append(decoder.number_of_computiations)\n",
    "        if verbose:\n",
    "            print(f'Transcription: {transcription} || Prediction: {words} || (nsub, ndel, nin) :{error_counts}')\n",
    "    \n",
    "    efficancy_measures = (decoding_time, backtrace_time, number_of_computations)\n",
    "    return all_losses, efficancy_measures\n",
    "\n",
    "\n",
    "lex = parse_lexicon('lexicon.txt')\n",
    "word_table, phone_table, state_table = generate_symbol_tables(lex)\n",
    "f = create_wfst()\n",
    "f_silence = create_wfst_with_silance()\n",
    "f_det = fst.determinize(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((116, 230), (84, 183))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_of_wfst(f), memory_of_wfst(f_det)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp_dict= {\n",
    "    'loss' : [],\n",
    "    'efficancy':[],\n",
    "    'acc': [],\n",
    "    'm1': [],\n",
    "    'm2': [],\n",
    "    'm3': []\n",
    "    \n",
    "}\n",
    "prune_thresholds = [i*5 for i in range(1,21)]\n",
    "verbose = False\n",
    "for prune_threshold in prune_thresholds:\n",
    "    print(f'Threshold = {prune_threshold}')\n",
    "    all_losses, efficancy_measures = decoding_loop(f, train_set=True, train_split=0.5, use_pruning=True, prune_threshold=prune_threshold, verbose=verbose)\n",
    "    avg_wer = get_avg_wer(all_losses, verbose=True)\n",
    "    m1,m2,m3 = get_avg_effciency(efficancy_measures, verbose=verbose)\n",
    "    exp_dict['loss'].append(all_losses)\n",
    "    exp_dict['efficancy'].append(efficancy_measures)\n",
    "    exp_dict['acc'].append(avg_wer)\n",
    "    exp_dict['m1'].append(m1)\n",
    "    exp_dict['m2'].append(m2)\n",
    "    exp_dict['m3'].append(m3)\n",
    "    print('\\n\\n\\n')\n",
    "    file_name = f'exp_dict_baseline_ours_{prune_threshold}.pkl'\n",
    "    with open(file_name, 'wb') as handler:\n",
    "        pickle.dump(exp_dict, handler)\n",
    "    print(f'saved to {file_name}')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ======================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wer\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from vetrbi import MyViterbiDecoder\n",
    "from utils import parse_lexicon, generate_symbol_tables\n",
    "\n",
    "\n",
    "lex = parse_lexicon('lexicon.txt')\n",
    "word_table, phone_table, state_table = generate_symbol_tables(lex)\n",
    "\n",
    "\n",
    "def read_transcription(wav_file):\n",
    "    \"\"\"\n",
    "    Get the transcription corresponding to wav_file.\n",
    "    \"\"\"\n",
    "    \n",
    "    transcription_file = os.path.splitext(wav_file)[0] + '.txt'\n",
    "    \n",
    "    with open(transcription_file, 'r') as f:\n",
    "        transcription = f.readline().strip()\n",
    "    \n",
    "    return transcription\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hmm import generate_word_sequence_recognition_wfst\n",
    "from hmm import generate_word_sequence_recognition_wfst_with_silance\n",
    "from hmm import generate_lexical_hmm\n",
    "\n",
    "def create_wfst():\n",
    "    f = generate_word_sequence_recognition_wfst(3)\n",
    "    f.set_input_symbols(state_table)\n",
    "    f.set_output_symbols(phone_table)\n",
    "    return f\n",
    "\n",
    "def create_wfst_with_silance():\n",
    "    f = generate_word_sequence_recognition_wfst_with_silance(3, use_unigram_probs=False)\n",
    "    f.set_input_symbols(state_table)\n",
    "    f.set_output_symbols(phone_table)\n",
    "    return f\n",
    "\n",
    "def create_lexical():\n",
    "    f = generate_lexical_hmm(1, use_unigram_probs=False)\n",
    "    f.set_input_symbols(state_table)\n",
    "    f.set_output_symbols(phone_table)\n",
    "    return f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = create_wfst()\n",
    "f_silence = create_wfst_with_silance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openfst_python as fst\n",
    "from subprocess import check_call\n",
    "from IPython.display import Image\n",
    "f_silence = fst.determinize(f_silence)\n",
    "f_silence.draw('tmp.dot', portrait=True)\n",
    "check_call(['dot','-Tpng','-Gdpi=400','tmp.dot','-o','tmp.png'])\n",
    "Image(filename='tmp.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_losses = []\n",
    "decoding_time = []\n",
    "backtrace_time = []\n",
    "number_of_computations = []\n",
    "i = 0\n",
    "train_split = int(0.85 * len(glob.glob('/group/teaching/asr/labs/recordings/*.wav')))  # replace path if using your own audio files\n",
    "print(train_split)\n",
    "\n",
    "all_transcriptions = ''\n",
    "for wav_file in tqdm(glob.glob('/group/teaching/asr/labs/recordings/*.wav')):    # replace path if using your own\n",
    "                                                                           # audio files\n",
    "    \n",
    "    decoder  = MyViterbiDecoder(f_silence, wav_file, verbose=False, use_pruning=False, determinized=True)\n",
    "    decoder.decode()\n",
    "    (state_path, words) = decoder.backtrace()  \n",
    "    \n",
    "    transcription = read_transcription(wav_file)\n",
    "    all_transcriptions += transcription + ' '\n",
    "    error_counts = wer.compute_alignment_errors(transcription, words)\n",
    "    word_count = len(transcription.split())\n",
    "\n",
    "    all_losses.append((error_counts, word_count))\n",
    "    decoding_time.append(decoder.decode_time)\n",
    "    backtrace_time.append(decoder.backtrace_time)\n",
    "    number_of_computations.append(decoder.number_of_computiations)\n",
    "    i += 1\n",
    "    if i == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the WER fo each file\n",
    "import numpy as np\n",
    "all_wer = []\n",
    "for error_counts, word_count in all_losses:\n",
    "    all_wer.append(sum(error_counts) / word_count)\n",
    "\n",
    "\n",
    "\n",
    "print(f'The average WER is {np.mean(all_wer):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print dcoding time statistics\n",
    "print(f'The average decoding time is {np.mean(decoding_time):.2f} seconds')\n",
    "print(f'The average backtrace time is {np.mean(backtrace_time):.2f} seconds')\n",
    "print(f'The average number of computations is {np.mean(number_of_computations):.2f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count unigram counts in all_transcriptions\n",
    "unigram_counts = {}\n",
    "for word in all_transcriptions.split():\n",
    "    if word in unigram_counts:\n",
    "        unigram_counts[word] += 1\n",
    "    else:\n",
    "        unigram_counts[word] = 1\n",
    "\n",
    "\n",
    "\n",
    "print('Unigram counts:' ,unigram_counts)\n",
    "unigram_probs = {}\n",
    "for word, count in unigram_counts.items():\n",
    "    unigram_probs[word] = count / sum(unigram_counts.values())\n",
    "\n",
    "print('Unigram probs:' ,unigram_probs)\n",
    "# save unigram probs to pickle file\n",
    "import pickle\n",
    "with open('unigram_probs.pickle', 'wb') as handle:\n",
    "    pickle.dump(unigram_probs, handle)\n",
    "    # load unigram probs from pickle file\n",
    "import pickle\n",
    "with open('unigram_probs.pickle', 'rb') as handle:\n",
    "    unigram_probs = pickle.load(handle)\n",
    "\n",
    "print('Unigram probs:' ,unigram_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wer\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from vetrbi import MyViterbiDecoder\n",
    "from utils import parse_lexicon, generate_symbol_tables, draw\n",
    "import openfst_python as fst\n",
    "\n",
    "\n",
    "\n",
    "lex = parse_lexicon('lexicon.txt')\n",
    "word_table, phone_table, state_table = generate_symbol_tables(lex)\n",
    "\n",
    "\n",
    "def read_transcription(wav_file):\n",
    "    \"\"\"\n",
    "    Get the transcription corresponding to wav_file.\n",
    "    \"\"\"\n",
    "    \n",
    "    transcription_file = os.path.splitext(wav_file)[0] + '.txt'\n",
    "    \n",
    "    with open(transcription_file, 'r') as f:\n",
    "        transcription = f.readline().strip()\n",
    "    \n",
    "    return transcription\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hmm import generate_word_sequence_recognition_wfst\n",
    "from hmm import generate_word_sequence_recognition_wfst_with_silance\n",
    "from hmm import generate_bigram_wfst\n",
    "\n",
    "def create_wfst():\n",
    "    f = generate_word_sequence_recognition_wfst(3)\n",
    "    f.set_input_symbols(state_table)\n",
    "    f.set_output_symbols(phone_table)\n",
    "    return f\n",
    "\n",
    "def create_wfst_with_silance():\n",
    "    f = generate_word_sequence_recognition_wfst_with_silance(3, use_unigram_probs=False)\n",
    "    f.set_input_symbols(state_table)\n",
    "    f.set_output_symbols(phone_table)\n",
    "    return f\n",
    "\n",
    "def create_lexical():\n",
    "    f = generate_lexical_hmm(1, use_unigram_probs=False)\n",
    "    f.set_input_symbols(state_table)\n",
    "    f.set_output_symbols(phone_table)\n",
    "    return f\n",
    "\n",
    "def create_bigram_lexical():\n",
    "    f = generate_bigram_wfst(1)\n",
    "    f.set_input_symbols(state_table)\n",
    "    f.set_output_symbols(phone_table)\n",
    "    return f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_losses = []\n",
    "decoding_time = []\n",
    "backtrace_time = []\n",
    "number_of_computations = []\n",
    "i = 0\n",
    "train_split = int(0.85 * len(glob.glob('/group/teaching/asr/labs/recordings/*.wav')))  # replace path if using your own audio files\n",
    "print(train_split)\n",
    "\n",
    "all_transcriptions = ''\n",
    "for wav_file in tqdm(glob.glob('/group/teaching/asr/labs/recordings/*.wav')):    # replace path if using your own\n",
    "                                                                           # audio files\n",
    "    \n",
    "    decoder  = MyViterbiDecoder(f, wav_file, verbose=False, use_pruning=False, determinized=True, bigram = True)\n",
    "    decoder.decode()\n",
    "    (state_path, words) = decoder.backtrace()  \n",
    "    \n",
    "    transcription = read_transcription(wav_file)\n",
    "    all_transcriptions += transcription + ' '\n",
    "    error_counts = wer.compute_alignment_errors(transcription, words)\n",
    "    word_count = len(transcription.split())\n",
    "\n",
    "    all_losses.append((error_counts, word_count))\n",
    "    decoding_time.append(decoder.decode_time)\n",
    "    backtrace_time.append(decoder.backtrace_time)\n",
    "    number_of_computations.append(decoder.number_of_computiations)\n",
    "    print(words)\n",
    "    print(transcription)\n",
    "    i += 1\n",
    "    if i == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the WER fo each file\n",
    "import numpy as np\n",
    "all_wer = []\n",
    "for error_counts, word_count in all_losses:\n",
    "    all_wer.append(sum(error_counts) / word_count)\n",
    "\n",
    "\n",
    "\n",
    "print(f'The average WER is {np.mean(all_wer):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print dcoding time statistics\n",
    "print(f'The average decoding time is {np.mean(decoding_time):.2f} seconds')\n",
    "print(f'The average backtrace time is {np.mean(backtrace_time):.2f} seconds')\n",
    "print(f'The average number of computations is {np.mean(number_of_computations):.2f}')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "8696358051874a88c1d2911df8bbed88795a658bdc69c38e8bd7d9488224210f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
